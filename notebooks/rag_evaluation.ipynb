{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Pipeline Evaluation — Tasks 5 & 6\n",
        "\n",
        "This notebook evaluates two retrieval pipelines for **Little Red Writing Room**:\n",
        "\n",
        "- **Option A (Baseline):** `RecursiveCharacterTextSplitter` + dense vector search + Cohere rerank\n",
        "- **Option B (Advanced):** `SemanticChunker` + LLM taxonomy classification + filtered retrieval + Cohere rerank\n",
        "\n",
        "Both pipelines use in-memory Qdrant, OpenAI `text-embedding-3-small`, and the same RAG prompt.\n",
        "RAGAS metrics provide the quantitative comparison at the end.\n",
        "\n",
        "See [ARCHITECTURE.md](../docs/ARCHITECTURE.md) for full pipeline descriptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 1: Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
        "\n",
        "if not os.environ.get(\"COHERE_API_KEY\"):\n",
        "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key: \")\n",
        "\n",
        "if not os.environ.get(\"LANGCHAIN_API_KEY\"):\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith project: LRWR-RAG-Evaluation\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ.setdefault(\"LANGCHAIN_PROJECT\", \"LRWR-RAG-Evaluation\")\n",
        "print(f\"LangSmith project: {os.environ['LANGCHAIN_PROJECT']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 2: Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 documents\n",
            "  - /Users/nikos/n/rvm/little-red-writing-room/notebooks/sample_data/purplefrog-finds-her-brother.md (42,963 chars)\n",
            "  - /Users/nikos/n/rvm/little-red-writing-room/notebooks/sample_data/purplefrog-story-notes.md (39,817 chars)\n"
          ]
        }
      ],
      "source": [
        "from lib.data_loading import load_sample_documents\n",
        "\n",
        "raw_docs = load_sample_documents()\n",
        "print(f\"Loaded {len(raw_docs)} documents\")\n",
        "for doc in raw_docs:\n",
        "    print(f\"  - {doc.metadata['source']} ({len(doc.page_content):,} chars)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 3: Option A — Baseline Pipeline (Task 5)\n",
        "\n",
        "**Chunking:** `RecursiveCharacterTextSplitter` (500 chars, 50 overlap)  \n",
        "**Retrieval:** Dense vector similarity (k=10) + Cohere rerank  \n",
        "**Qdrant payload:** Minimal (text, source, chunk index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Option A chunks: 211\n",
            "\n",
            "Example chunk:\n",
            "–1–\n",
            "\n",
            "\"What's the function of a Worm?\" asked OchraMags. She was the junior instructor of the last surviving Sparky rebel colony in the Underground. Several kids raised their hands. Behind her at a distance, hanging by two thick cables from the ceiling of the giant terraformed tunnel, the big LED fire...\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "baseline_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"],\n",
        ")\n",
        "baseline_chunks = baseline_splitter.split_documents(raw_docs)\n",
        "print(f\"Option A chunks: {len(baseline_chunks)}\")\n",
        "print(f\"\\nExample chunk:\\n{baseline_chunks[0].page_content[:300]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "option_a_vectorstore = QdrantVectorStore.from_documents(\n",
        "    baseline_chunks,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"option_a_baseline\",\n",
        ")\n",
        "option_a_retriever = option_a_vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor_a = CohereRerank(model=\"rerank-v3.5\")\n",
        "option_a_rerank_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor_a,\n",
        "    base_retriever=option_a_retriever,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.chains import build_rag_chain\n",
        "\n",
        "option_a_chain = build_rag_chain(option_a_rerank_retriever, chat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check — Option A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, PurpleFrog is faced with a critical choice: to reach her brother or to follow OchraMags's evacuation order. The context indicates that if PurpleFrog chooses to follow OchraMags, she risks not seeing her brother again (\"Follows: she risks not seeing her brother again\"). Conversely, if she chooses to escape using OchraMags's MODR (a device mentioned in the notes), she risks not making it to safety (\"Escapes: she risks not making it to safety\"). \n",
            "\n",
            "Additionally, there is a scene where OchraMags surrenders and offers to take PurpleFrog to her brother, saying, \"Stop,\" she breathed, \"Don’t do anything stupid, newb. I’ll take you to your brother. I promise.\" This suggests that if PurpleFrog prioritizes reaching her brother, she might accept OchraMags's offer.\n",
            "\n",
            "Therefore, if PurpleFrog had to choose, the evidence implies she would prioritize reuniting with her brother, even if it means risking the consequences of defying evacuation orders. She seems motivated by a desire to reunite or stay with her family, which aligns with her willingness to risk not making it to safety and the offer from OchraMags to facilitate that reunion.\n"
          ]
        }
      ],
      "source": [
        "response = option_a_chain.invoke(\n",
        "    {\"question\": \"If PurpleFrog had to choose between reaching her brother and following OchraMags's evacuation order, what would she do?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, PurpleFrog seems to have a complex attitude toward the Underground. She recognizes that the Worms keep the Underground functioning and that they were created to suppress or \"zero out\" people like her and her brother. This indicates a negative view of the Underground, associating it with control and oppression. \n",
            "\n",
            "Furthermore, her desire to hide in the Overground, especially after seeing light coming out from a big hole at the top, suggests she is eager to escape or avoid the Underground and its associated threats. She does not want to be back where the worms are, implying a negative or wary feeling about the Underground.\n",
            "\n",
            "Overall, PurpleFrog appears to feel negatively about the Underground, viewing it as a place of control, suppression, or danger, and prefers to be elsewhere, notably in the Overground, which she seems to see as a safer or freer space.\n"
          ]
        }
      ],
      "source": [
        "response = option_a_chain.invoke(\n",
        "    {\"question\": \"How does PurpleFrog feel about the Underground?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Ytterbium Entangler is described as a mythic artifact that the rebels have been searching for centuries. In the story, it is a crucial device used by the time travelers SnowRaven and PurpleFrog to jump to a specific space-time point—specifically, a moment before WormWood built the Worms. Its significance lies in its immense value and almost legendary status, as it enables these advanced time manipulations and time jumps. \n",
            "\n",
            "For the story, the Ytterbium Entangler represents a pivotal element that could grant the rebels—and by extension, the main characters—power to alter history and potentially achieve true freedom. It signifies hope, mystery, and a long-standing quest, making it a central focus of the narrative's tension and stakes. The mention of it being \"mythic\" also suggests that acquiring or controlling the Ytterbium Entangler could be a turning point, possibly enabling the protagonists to rewrite the past and influence their future.\n"
          ]
        }
      ],
      "source": [
        "response = option_a_chain.invoke(\n",
        "    {\"question\": \"What is the Ytterbium Entangler and what does it mean for the story?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 4: Option B — Advanced Pipeline (Task 6)\n",
        "\n",
        "**Chunking:** `SemanticChunker` (percentile threshold on embedding similarity) + content overlap (3 sentences)  \n",
        "**Classification:** LLM pass per chunk producing taxonomy metadata  \n",
        "**Metadata title prepend:** Compact `[content_type | narrative_function | characters: … ]` header baked into each chunk's text before embedding  \n",
        "**Retrieval:** Dense vector similarity (k=10) + Cohere rerank  \n",
        "**Qdrant payload:** Full taxonomy tags (content_type, narrative_function, characters_present, etc.)\n",
        "\n",
        "### Expected performance\n",
        "\n",
        "We expect Option B to improve over the baseline in several areas:\n",
        "\n",
        "- **Context precision:** Semantic chunking keeps related content coherent\n",
        "  rather than splitting across arbitrary boundaries, and the taxonomy\n",
        "  metadata enriches the Qdrant payload so that filtered retrieval reduces\n",
        "  irrelevant chunks before Cohere reranking.\n",
        "\n",
        "- **Context recall:** Option A's 500-char chunks frequently omit character\n",
        "  names because mid-scene passages use pronouns or implicit references, making\n",
        "  them invisible to character-focused dense similarity queries. Option B addresses\n",
        "  this in two ways: (1) larger semantic units are more likely to contain character\n",
        "  names explicitly in `page_content`, and (2) the classification pass resolves\n",
        "  pronouns and aliases into canonical names stored in `characters_present` in\n",
        "  each chunk's Qdrant payload, enabling filtered retrieval once activated.\n",
        "\n",
        "- **Faithfulness:** The enriched metadata gives the LLM better-grounded\n",
        "  context, reducing the chance of hallucination into undefined character\n",
        "  attributes.\n",
        "\n",
        "- **Context entity recall:** The classification pass resolves pronouns and\n",
        "  aliases into canonical character names, which are then prepended to each\n",
        "  chunk's text as part of the metadata title before embedding. This means\n",
        "  character names are present in the embedded text even for chunks that use\n",
        "  pronouns in the original prose, so dense similarity search should surface\n",
        "  more entity-relevant chunks than Option A.\n",
        "\n",
        "- **Latency and cost:** We expect Option B to be slower and more expensive\n",
        "  per query because semantic chunks are larger (more tokens passed to the\n",
        "  LLM) and the pipeline includes an additional LLM classification pass\n",
        "  at indexing time.\n",
        "\n",
        "Cohere reranking is held constant across both pipelines, so the evaluation\n",
        "delta isolates the value of semantic chunking and taxonomy classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Option B semantic chunks: 57\n",
            "\n",
            "Example chunk:\n",
            "–1–\n",
            "\n",
            "\"What's the function of a Worm?\" asked OchraMags. She was the junior instructor of the last surviving Sparky rebel colony in the Underground. Several kids raised their hands. Behind her at a distance, hanging by two thick cables from the ceiling of the giant terraformed tunnel, the big LED fire...\n"
          ]
        }
      ],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\",\n",
        ")\n",
        "semantic_chunks = semantic_chunker.split_documents(raw_docs)\n",
        "print(f\"Option B semantic chunks: {len(semantic_chunks)}\")\n",
        "print(f\"\\nExample chunk:\\n{semantic_chunks[0].page_content[:300]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Content overlap — unit test\n",
        "\n",
        "Verify `apply_semantic_overlap` on toy fixtures before processing real data.\n",
        "No API calls required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apply_semantic_overlap unit tests passed ✓\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from lib.chunking import apply_semantic_overlap\n",
        "\n",
        "# --- toy fixtures with known sentence counts ---\n",
        "_A = Document(page_content=\"Sentence one. Sentence two. Sentence three. Sentence four.\")\n",
        "_B = Document(page_content=\"Sentence five. Sentence six. Sentence seven.\")\n",
        "_C = Document(page_content=\"Sentence eight. Sentence nine.\")\n",
        "\n",
        "_result = apply_semantic_overlap([_A, _B, _C], overlap_sentences=2)\n",
        "\n",
        "# chunk 0 is untouched\n",
        "assert _result[0].page_content == _A.page_content, \"Chunk 0 should be unchanged\"\n",
        "assert _result[0].metadata[\"overlap_sentence_count\"] == 0\n",
        "\n",
        "# chunk 1 starts with the last 2 sentences of chunk 0's original text\n",
        "assert \"Sentence three.\" in _result[1].page_content\n",
        "assert \"Sentence four.\" in _result[1].page_content\n",
        "assert _result[1].page_content.index(\"Sentence three.\") < _result[1].page_content.index(\"Sentence five.\")\n",
        "assert _result[1].metadata[\"overlap_sentence_count\"] == 2\n",
        "\n",
        "# chunk 2 sources its overlap from chunk 1's *original* text (not the already-overlapped version)\n",
        "assert \"Sentence six.\" in _result[2].page_content\n",
        "assert \"Sentence seven.\" in _result[2].page_content\n",
        "assert _result[2].page_content.index(\"Sentence six.\") < _result[2].page_content.index(\"Sentence eight.\")\n",
        "assert _result[2].metadata[\"overlap_sentence_count\"] == 2\n",
        "\n",
        "print(\"apply_semantic_overlap unit tests passed ✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply content overlap to semantic chunks\n",
        "\n",
        "Each chunk (except the first) has the last `OVERLAP_SENTENCES` sentences of its\n",
        "predecessor prepended. This preserves cross-boundary context for both the\n",
        "classification pass (Stage 3) and for retrieval at query time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overlapped chunks: 57  (overlap window: 3 sentences)\n",
            "\n",
            "Overlap prefix example — chunk 1:\n",
            "\"TELL ME U MISS WALKIN BAREFOOT AND SILK KIMONOS OR I LL MAKE U SMELL THESE STUPID BOOTS ,\" she texted her brother through her standard-issued rebel \"terminal\". When he didn't respond she hid the terminal behind the metal crate and fired up an \"anime\" she'd discovered in the depths of the colony's data stash – a girl and her pet running in green fields of grass under mountains. Just like home.\n",
            "\n",
            "If...\n"
          ]
        }
      ],
      "source": [
        "OVERLAP_SENTENCES = 3\n",
        "overlapped_chunks = apply_semantic_overlap(semantic_chunks, overlap_sentences=OVERLAP_SENTENCES)\n",
        "print(f\"Overlapped chunks: {len(overlapped_chunks)}  (overlap window: {OVERLAP_SENTENCES} sentences)\")\n",
        "print(f\"\\nOverlap prefix example — chunk 1:\\n{overlapped_chunks[1].page_content[:400]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Taxonomy classification pass\n",
        "\n",
        "Each chunk gets an LLM call that produces structured metadata (content type,\n",
        "narrative function, characters present, Story Grid tag, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/57] dialogue / character_reveal — ['OchraMags', 'PurpleFrog']\n",
            "[2/57] internal_monologue / character_reveal — ['OchraMags']\n",
            "[3/57] dialogue / worldbuilding — ['PurpleFrog', 'OzzieHeron', 'WormWood']\n",
            "[4/57] description / character_reveal — ['PurpleFrog', 'WormWood']\n",
            "[5/57] dialogue / plot_event — ['PurpleFrog', 'OchraMags', 'OzzieHeron', 'WormWood']\n",
            "[6/57] dialogue / plot_event — ['PurpleFrog', 'OchraMags']\n",
            "[7/57] dialogue / plot_event — ['PurpleFrog', 'OchraMags']\n",
            "[8/57] dialogue / plot_event — ['PurpleFrog', 'OchraMags', 'SnowRaven', 'WormWood']\n",
            "[9/57] action_reaction / plot_event — ['SnowRaven', 'PurpleFrog', 'OchraMags']\n",
            "[10/57] action_reaction / plot_event — ['OchraMags', 'PurpleFrog']\n",
            "[11/57] action_reaction / plot_event — ['OchraMags', 'PurpleFrog']\n",
            "[12/57] action_reaction / plot_event — ['MyaxSerp']\n",
            "[13/57] action_reaction / character_reveal — ['PurpleFrog', 'MyaxSerp', 'OchraMags']\n",
            "[14/57] dialogue / plot_event — ['PurpleFrog', 'MyaxSerp', 'OchraMags']\n",
            "[15/57] action_reaction / plot_event — ['PurpleFrog', 'MyaxSerp', 'OzzieHeron']\n",
            "[16/57] action_reaction / plot_event — ['OzzieHeron', 'WormWood']\n",
            "[17/57] dialogue / plot_event — ['OzzieHeron']\n",
            "[18/57] dialogue / plot_event — ['OzzieHeron']\n",
            "[19/57] dialogue / plot_event — ['OzzieHeron', 'WormWood', 'PurpleFrog']\n",
            "[20/57] action_reaction / plot_event — ['PurpleFrog', 'OzzieHeron', 'OchraMags', 'WormWood']\n",
            "[21/57] action_reaction / plot_event — ['OchraMags', 'PurpleFrog', 'OzzieHeron', 'WormWood']\n",
            "[22/57] action_reaction / plot_event — ['PurpleFrog', 'WormWood']\n",
            "[23/57] action_reaction / plot_event — ['PurpleFrog', 'WormWood']\n",
            "[24/57] action_reaction / plot_event — ['PurpleFrog', 'WormWood', 'OchraMags', 'MyaxSerp']\n",
            "[25/57] dialogue / worldbuilding — ['WormWood']\n",
            "[26/57] dialogue / character_reveal — ['WormWood', 'PurpleFrog']\n",
            "[27/57] dialogue / plot_event — ['PurpleFrog', 'SnowRaven', 'WormWood', 'OchraMags', 'MyaxSerp', 'OzzieHeron']\n",
            "[28/57] dialogue / plot_event — ['PurpleFrog']\n",
            "[29/57] dialogue / plot_event — ['PurpleFrog']\n",
            "[30/57] dialogue / plot_event — []\n",
            "[31/57] dialogue / plot_event — []\n",
            "[32/57] action_reaction / plot_event — ['PurpleFrog']\n",
            "[33/57] dialogue / plot_event — ['PurpleFrog']\n",
            "[34/57] dialogue / plot_event — []\n",
            "[35/57] dialogue / plot_event — []\n",
            "[36/57] dialogue / plot_event — []\n",
            "[37/57] dialogue / worldbuilding — ['PurpleFrog']\n",
            "[38/57] dialogue / worldbuilding — ['SnowRaven', 'PurpleFrog', 'WormWood']\n",
            "[39/57] dialogue / worldbuilding — ['SnowRaven', 'PurpleFrog', 'WormWood']\n",
            "[40/57] dialogue / plot_event — []\n",
            "[41/57] description / plot_event — ['PurpleFrog', 'OchraMags', 'WormWood']\n",
            "[42/57] internal_monologue / character_reveal — ['PurpleFrog']\n",
            "[43/57] internal_monologue / plot_event — ['PurpleFrog', 'MyaxSerp']\n",
            "[44/57] action_reaction / plot_event — ['MyaxSerp']\n",
            "[45/57] description / worldbuilding — ['OzzieHeron', 'WormWood']\n",
            "[46/57] description / worldbuilding — ['PurpleFrog', 'OzzieHeron']\n",
            "[47/57] internal_monologue / plot_event — ['OzzieHeron', 'PurpleFrog']\n",
            "[48/57] internal_monologue / plot_event — ['PurpleFrog', 'OzzieHeron', 'WormWood']\n",
            "[49/57] action_reaction / thematic — ['OzzieHeron', 'WormWood', 'PurpleFrog']\n",
            "[50/57] description / plot_event — ['PurpleFrog']\n",
            "[51/57] action_reaction / plot_event — ['PurpleFrog', 'SnowRaven']\n",
            "[52/57] internal_monologue / character_reveal — ['PurpleFrog', 'SnowRaven', 'WormWood']\n",
            "[53/57] internal_monologue / plot_event — ['PurpleFrog', 'SnowRaven', 'WormWood']\n",
            "[54/57] internal_monologue / thematic — ['PurpleFrog', 'SnowRaven']\n",
            "[55/57] description / worldbuilding — ['Sam']\n",
            "[56/57] description / worldbuilding — []\n",
            "[57/57] description / worldbuilding — []\n"
          ]
        }
      ],
      "source": [
        "import importlib, lib.classification; importlib.reload(lib.classification)\n",
        "from lib.classification import classify_chunks\n",
        "\n",
        "known_characters = [\n",
        "    \"PurpleFrog\",\n",
        "    \"SnowRaven\",\n",
        "    \"OchraMags\",\n",
        "    \"OzzieHeron\",\n",
        "    \"MyaxSerp\",\n",
        "    \"WormWood\",\n",
        "]\n",
        "\n",
        "classification_llm = ChatOpenAI(model=\"gpt-4.1-mini\", max_completion_tokens=500)\n",
        "enriched_chunks = classify_chunks(\n",
        "    overlapped_chunks, known_characters, classification_llm, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Titled chunks: 57\n",
            "\n",
            "Example titled chunk:\n",
            "[dialogue | character_reveal | characters: OchraMags, PurpleFrog]\n",
            "\n",
            "–1–\n",
            "\n",
            "\"What's the function of a Worm?\" asked OchraMags. She was the junior instructor of the last surviving Sparky rebel colony in the Underground. Several kids raised their hands. Behind her at a distance, hanging by two thick cables from the ceiling of the giant terraformed tunnel, the big LED firefly screen read: \n",
            "\n",
            "\"*Days since l...\n"
          ]
        }
      ],
      "source": [
        "from lib.chunking import prepend_metadata_title\n",
        "\n",
        "titled_chunks = prepend_metadata_title(enriched_chunks)\n",
        "print(f\"Titled chunks: {len(titled_chunks)}\")\n",
        "print(f\"\\nExample titled chunk:\\n{titled_chunks[0].page_content[:400]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': '/Users/nikos/n/rvm/little-red-writing-room/notebooks/sample_data/purplefrog-finds-her-brother.md',\n",
              " 'overlap_sentence_count': 0,\n",
              " 'content_type': 'dialogue',\n",
              " 'narrative_function': 'character_reveal',\n",
              " 'characters_present': ['OchraMags', 'PurpleFrog'],\n",
              " 'story_grid_tag': 'none',\n",
              " 'external_references': ['anime'],\n",
              " 'implied_gaps': ['What is the role or function of a Worm in this world?',\n",
              "  'What is the significance of the Sparky rebel colony and their opposition to the Worms?',\n",
              "  \"Why hasn't PurpleFrog's brother responded to her message?\",\n",
              "  'What is the setting and broader context of the terraformed tunnel and the underground colony?']}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enriched_chunks[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Option B vector store with metadata-titled chunks\n",
        "\n",
        "Each `titled_chunk` has a compact taxonomy header prepended to its text before\n",
        "embedding, for example:\n",
        "\n",
        "```\n",
        "[dialogue | plot_event | characters: PurpleFrog, OchraMags | turning_point]\n",
        "\n",
        "\"Tell me you miss walking barefoot...\"\n",
        "```\n",
        "\n",
        "Baking the taxonomy into the `page_content` means dense similarity search\n",
        "naturally rewards chunks whose `content_type`, `narrative_function`, and\n",
        "`characters_present` align with the query — no Qdrant filter API required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "option_b_vectorstore = QdrantVectorStore.from_documents(\n",
        "    titled_chunks,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"option_b_advanced\",\n",
        ")\n",
        "option_b_retriever = option_b_vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "compressor_b = CohereRerank(model=\"rerank-v3.5\")\n",
        "option_b_rerank_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor_b,\n",
        "    base_retriever=option_b_retriever,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "option_b_chain = build_rag_chain(option_b_rerank_retriever, chat_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sanity check — Option B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, PurpleFrog's primary motivation is to reach her brother, which she considers more important than following OchraMags's evacuation protocol. \n",
            "\n",
            "The context indicates that during the crisis, PurpleFrog is desperate to contact her brother and even risks her safety to do so. She actively seeks to contact him by plucking her terminal out of OchraMags's grasp and attempting to call him from the over-pipes, showing her willingness to prioritize her bond with her brother over strictly adhering to the evacuation protocol enforced by OchraMags.\n",
            "\n",
            "Furthermore, the narrative suggests that PurpleFrog perceives her brother's safety as her \"home,\" and her actions—stealing the MODR (a device to fly out)—demonstrate her commitment to reaching him rather than obeying strict authority or protocols. She is aware that following OchraMags's instructions might keep her safe temporarily but is willing to take significant risks (risking not making it to safety or her own injury) in order to locate her brother.\n",
            "\n",
            "**Therefore, if PurpleFrog had to choose between reaching her brother and following OchraMags’s evacuation order, she would choose to reach her brother.**\n"
          ]
        }
      ],
      "source": [
        "response = option_b_chain.invoke(\n",
        "    {\"question\": \"If PurpleFrog had to choose between reaching her brother and following OchraMags's evacuation order, what would she do?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, PurpleFrog's feelings about the Underground are complex. She perceives the Underground as a refuge or hiding place, especially after she observes the light coming from a big hole at the top, indicating a way back to the Overground or perhaps a safer area. She explicitly states her desire to \"hide in the Overground especially after she sees light coming out from a big hole at the top. Not back where the worms are!!\" This suggests she sees the Underground as a temporary safe space or retreat rather than a permanent home.\n",
            "\n",
            "Additionally, her interactions with WormWood and her brother imply a certain awareness of the Underground's significance. WormWood built the Underground to feed the Overground, which indicates she recognizes it as a constructed space with strategic importance. She considers reading the server logs WormWood mentions, indicating she is curious about or values the information stored there—possibly seeing the Underground as a place that holds critical knowledge or secrets.\n",
            "\n",
            "Her emotions toward the Underground seem to be driven by a focus on safety and escape, rather than affection or attachment. She wants to avoid the risks associated with being near Worms and prefers to stay away from the WormWood-controlled areas. Overall, PurpleFrog feels somewhat cautious and strategic about the Underground: she sees it as a necessary refuge but not as a place she wishes to stay in permanently or deeply connect with emotionally.\n"
          ]
        }
      ],
      "source": [
        "response = option_b_chain.invoke(\n",
        "    {\"question\": \"How does PurpleFrog feel about the Underground?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, the Ytterbium Entangler is a mythic artifact that the rebels have been searching for centuries. It is the key device that enables the time travelers, SnowRaven and PurpleFrog, to jump to a space-time point before WormWood built the Worms. Its significance for the story is that capturing or controlling the Ytterbium Entangler could allow the protagonists to prevent WormWood from creating the deadly \"gassing Worms,\" thereby potentially altering the course of history and achieving their goal of stopping WormWood's destructive plans. It represents a pivotal object of pursuit that embodies hope for change and is central to the worldbuilding and the characters' motivations in the narrative.\n"
          ]
        }
      ],
      "source": [
        "response = option_b_chain.invoke(\n",
        "    {\"question\": \"What is the Ytterbium Entangler and what does it mean for the story?\"}\n",
        ")\n",
        "print(response[\"response\"].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 5: RAGAS Evaluation\n",
        "\n",
        "Generate a synthetic test dataset from the raw documents, then evaluate both\n",
        "pipelines against it using RAGAS metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate synthetic test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e11a0dcda1d4a34b7c22eed1a745260",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56f52e3f87d04708abc142dd99f1d169",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53b8aa1142f348168569fe64af6545ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6e9fbdd6e614dc284103ad9058e9f26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01b37f2b36864d8493e87cae2063ba68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5844cca53e4456af05a324f6a0bfc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa90abbdb9604dd89dc0b4dc45bd3d1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a71d296ee424fc496f0a787c8c667af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4275868a2f48d78803df6c19fe8d20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))  # type: ignore[arg-type]\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(raw_docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the PFrog and why is it important in t...</td>\n",
              "      <td>[# Scene Planning Attack of the Worms Short St...</td>\n",
              "      <td>In the story, PFrog refers to PurpleFrog (also...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is the SnowRaven in the context of the sce...</td>\n",
              "      <td>[## Scene 2: Steal The Comms | 1\\. What are th...</td>\n",
              "      <td>SnowRaven, also known as Chion Cas, is a chara...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is Purplefrog?</td>\n",
              "      <td>[## Scene 3: Evacuate Or Escape | 1\\. What are...</td>\n",
              "      <td>PurpleFrog (aka Mauve Cal) is the Protagonist ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the context of the scene where PurpleFrog i...</td>\n",
              "      <td>[## Scene 4: Chased By A Worm | 1\\. What are t...</td>\n",
              "      <td>PurpleFrog is the protagonist, also known as M...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wha crisis involve a choise to loosn grip or s...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n## Scene 2: Steal The Comms | 1\\. ...</td>\n",
              "      <td>In the scene where PurpleFrog faces the crisis...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the story illustrate that safety can ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n# Scene Planning Attack of the Wor...</td>\n",
              "      <td>The story demonstrates that safety is not sole...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the themes of character struggle with s...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n## Scene 2: Steal The Comms | 1\\. ...</td>\n",
              "      <td>In the first scene, PurpleFrog faces the chall...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do the choices and consequences faced by P...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n# Scene Planning Attack of the Wor...</td>\n",
              "      <td>In the first scene, PurpleFrog faces the crisi...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How do the worms in both scenes demonstrate th...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n## Scene 4: Chased By A Worm | 1\\....</td>\n",
              "      <td>In the first scene, the worms act as environme...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How do the themes of resilience and trust, exe...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n## Scene 3: Evacuate Or Escape | 1...</td>\n",
              "      <td>In the provided context, Mauve Cal, also known...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How does the story of the Purplefrog illustrat...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n# Scene Planning Attack of the Wor...</td>\n",
              "      <td>The story of the Purplefrog demonstrates resil...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do the themes of SnowRaven illustrate the ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\n## Scene 2: Steal The Comms | 1\\. ...</td>\n",
              "      <td>The themes of SnowRaven are reflected in the p...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What is the PFrog and why is it important in t...   \n",
              "1   Who is the SnowRaven in the context of the sce...   \n",
              "2                                 What is Purplefrog?   \n",
              "3   In the context of the scene where PurpleFrog i...   \n",
              "4   Wha crisis involve a choise to loosn grip or s...   \n",
              "5   How does the story illustrate that safety can ...   \n",
              "6   How do the themes of character struggle with s...   \n",
              "7   How do the choices and consequences faced by P...   \n",
              "8   How do the worms in both scenes demonstrate th...   \n",
              "9   How do the themes of resilience and trust, exe...   \n",
              "10  How does the story of the Purplefrog illustrat...   \n",
              "11  How do the themes of SnowRaven illustrate the ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [# Scene Planning Attack of the Worms Short St...   \n",
              "1   [## Scene 2: Steal The Comms | 1\\. What are th...   \n",
              "2   [## Scene 3: Evacuate Or Escape | 1\\. What are...   \n",
              "3   [## Scene 4: Chased By A Worm | 1\\. What are t...   \n",
              "4   [<1-hop>\\n\\n## Scene 2: Steal The Comms | 1\\. ...   \n",
              "5   [<1-hop>\\n\\n# Scene Planning Attack of the Wor...   \n",
              "6   [<1-hop>\\n\\n## Scene 2: Steal The Comms | 1\\. ...   \n",
              "7   [<1-hop>\\n\\n# Scene Planning Attack of the Wor...   \n",
              "8   [<1-hop>\\n\\n## Scene 4: Chased By A Worm | 1\\....   \n",
              "9   [<1-hop>\\n\\n## Scene 3: Evacuate Or Escape | 1...   \n",
              "10  [<1-hop>\\n\\n# Scene Planning Attack of the Wor...   \n",
              "11  [<1-hop>\\n\\n## Scene 2: Steal The Comms | 1\\. ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   In the story, PFrog refers to PurpleFrog (also...   \n",
              "1   SnowRaven, also known as Chion Cas, is a chara...   \n",
              "2   PurpleFrog (aka Mauve Cal) is the Protagonist ...   \n",
              "3   PurpleFrog is the protagonist, also known as M...   \n",
              "4   In the scene where PurpleFrog faces the crisis...   \n",
              "5   The story demonstrates that safety is not sole...   \n",
              "6   In the first scene, PurpleFrog faces the chall...   \n",
              "7   In the first scene, PurpleFrog faces the crisi...   \n",
              "8   In the first scene, the worms act as environme...   \n",
              "9   In the provided context, Mauve Cal, also known...   \n",
              "10  The story of the Purplefrog demonstrates resil...   \n",
              "11  The themes of SnowRaven are reflected in the p...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Option A (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47f3747bbdb94e1a9962d083dc69b275",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[0]: AttributeError('StringIO' object has no attribute 'classifications')\n",
            "Exception raised in Job[7]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[21]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[52]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[41]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[47]: AttributeError('StringIO' object has no attribute 'statements')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.3636, 'faithfulness': 0.6647, 'factual_correctness': 0.6744, 'answer_relevancy': 0.8533, 'context_entity_recall': 0.4583}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from lib.evaluation import evaluate_chain\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))  # type: ignore[arg-type]\n",
        "\n",
        "option_a_results = evaluate_chain(\n",
        "    option_a_chain.with_config({\"run_name\": \"option_a_baseline\"}),\n",
        "    dataset,\n",
        "    evaluator_llm,\n",
        ")\n",
        "option_a_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Option B (Advanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca5e5e1b8acf4be48dff5a6a2cc34518",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[0]: AttributeError('StringIO' object has no attribute 'classifications')\n",
            "Exception raised in Job[40]: AttributeError('StringIO' object has no attribute 'classifications')\n",
            "Exception raised in Job[2]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[7]: AttributeError('StringIO' object has no attribute 'statements')\n",
            "Exception raised in Job[52]: AttributeError('StringIO' object has no attribute 'statements')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8833, 'faithfulness': 0.9474, 'factual_correctness': 0.6867, 'answer_relevancy': 0.9277, 'context_entity_recall': 0.5514}"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "option_b_results = evaluate_chain(\n",
        "    option_b_chain.with_config({\"run_name\": \"option_b_advanced\"}),\n",
        "    dataset,\n",
        "    evaluator_llm,\n",
        ")\n",
        "option_b_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Section 6: Comparison\n",
        "\n",
        "Side-by-side RAGAS scores and delta analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Option A (Baseline)</th>\n",
              "      <th>Option B (Advanced)</th>\n",
              "      <th>delta</th>\n",
              "      <th>pct_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>context_recall</th>\n",
              "      <td>0.364</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.519</td>\n",
              "      <td>142.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>faithfulness</th>\n",
              "      <td>0.665</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.282</td>\n",
              "      <td>42.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>factual_correctness</th>\n",
              "      <td>0.674</td>\n",
              "      <td>0.687</td>\n",
              "      <td>0.013</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_relevancy</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.928</td>\n",
              "      <td>0.075</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_entity_recall</th>\n",
              "      <td>0.458</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.093</td>\n",
              "      <td>20.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Option A (Baseline)  Option B (Advanced)  delta  \\\n",
              "context_recall                       0.364                0.883  0.519   \n",
              "faithfulness                         0.665                0.947  0.282   \n",
              "factual_correctness                  0.674                0.687  0.013   \n",
              "answer_relevancy                     0.853                0.928  0.075   \n",
              "context_entity_recall                0.458                0.551  0.093   \n",
              "\n",
              "                       pct_change  \n",
              "context_recall              142.6  \n",
              "faithfulness                 42.4  \n",
              "factual_correctness           1.9  \n",
              "answer_relevancy              8.8  \n",
              "context_entity_recall        20.3  "
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from lib.evaluation import compare_results\n",
        "\n",
        "comparison_df = compare_results({\n",
        "    \"Option A (Baseline)\": option_a_results,\n",
        "    \"Option B (Advanced)\": option_b_results,\n",
        "})\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Option A (avg)</th>\n",
              "      <th>Option B (avg)</th>\n",
              "      <th>delta</th>\n",
              "      <th>pct_change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Latency (s)</th>\n",
              "      <td>2.915000</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>0.395000</td>\n",
              "      <td>13.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>909.916667</td>\n",
              "      <td>2693.416667</td>\n",
              "      <td>1783.500000</td>\n",
              "      <td>196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cost ($)</th>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000364</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>111.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Option A (avg)  Option B (avg)        delta  pct_change\n",
              "Latency (s)        2.915000        3.310000     0.395000        13.6\n",
              "Tokens           909.916667     2693.416667  1783.500000       196.0\n",
              "Cost ($)           0.000172        0.000364     0.000192       111.6"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "option_a_runs = pd.DataFrame({\n",
        "    \"latency_s\": [2.16, 2.59, 5.16, 4.49, 3.66, 3.74, 2.60, 2.96, 2.92, 1.76, 1.50, 1.44],\n",
        "    \"tokens\":    [864, 894, 954, 1087, 1073, 1006, 829, 988, 1002, 750, 728, 744],\n",
        "    \"cost\":      [0.0001644, 0.0001563, 0.0002055, 0.0002338, 0.0002261, 0.0002155,\n",
        "                  0.0001447, 0.000193, 0.0001938, 0.0001176, 0.0001085, 0.0001071],\n",
        "})\n",
        "\n",
        "option_b_runs = pd.DataFrame({\n",
        "    \"latency_s\": [4.20, 3.81, 5.60, 4.47, 3.19, 3.53, 2.75, 3.19, 2.52, 1.70, 2.97, 1.79],\n",
        "    \"tokens\":    [3337, 2902, 3198, 2908, 2960, 3007, 2780, 2059, 2628, 1308, 2704, 2530],\n",
        "    \"cost\":      [0.0004894, 0.0004039, 0.0004677, 0.0004072, 0.0004181, 0.0003955,\n",
        "                  0.000353, 0.0002911, 0.0003315, 0.0001548, 0.0003592, 0.000301],\n",
        "})\n",
        "\n",
        "avg_a = option_a_runs.mean()\n",
        "avg_b = option_b_runs.mean()\n",
        "\n",
        "langsmith_summary = pd.DataFrame({\n",
        "    \"Option A (avg)\": avg_a,\n",
        "    \"Option B (avg)\": avg_b,\n",
        "    \"delta\": avg_b - avg_a,\n",
        "    \"pct_change\": ((avg_b - avg_a) / avg_a * 100).round(1),\n",
        "}).rename(index={\"latency_s\": \"Latency (s)\", \"tokens\": \"Tokens\", \"cost\": \"Cost ($)\"})\n",
        "\n",
        "langsmith_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "\n",
        "- **Context recall (+142.6%, 0.364 → 0.883):** The strongest result. Option\n",
        "  A's fixed 500-char chunks frequently lack character names because mid-scene\n",
        "  passages rely on pronouns or implicit references, so character-focused dense\n",
        "  similarity queries fail to surface the relevant chunks. Option B addresses\n",
        "  this in two ways: (1) larger semantic units are self-contained narrative\n",
        "  passages far more likely to contain character names explicitly in\n",
        "  `page_content`, and (2) the classification pass resolves pronouns and aliases\n",
        "  into canonical names stored in `characters_present` within each chunk's\n",
        "  Qdrant payload.\n",
        "\n",
        "- **Faithfulness (+42.4%, 0.665 → 0.947):** A major improvement. Enriched,\n",
        "  self-contained semantic chunks give the LLM better grounding, significantly\n",
        "  reducing hallucination and unsupported claims in generated responses.\n",
        "\n",
        "- **Factual correctness (+1.9%, 0.674 → 0.687):** A small but positive gain.\n",
        "  Larger semantic chunks provide enough additional context for the LLM to\n",
        "  reason more accurately about specific story details without diluting\n",
        "  precision.\n",
        "\n",
        "- **Context entity recall (+20.3%, 0.458 → 0.551):** A meaningful improvement.\n",
        "  The classification pass extracts `characters_present` and other named\n",
        "  entities into chunk metadata, and that is included explicitly in the chunk so it's expected to have better recall even if their \"embedding\" contributions may be overshadowed by the rest of the chunk content.\n",
        "\n",
        "- **Answer relevancy (+8.8%, 0.853 → 0.928):** A solid improvement. Responses\n",
        "  generated from richer, more coherent context are better aligned to the\n",
        "  original question.\n",
        "\n",
        "- **Latency (+13.5%), tokens (+196%), cost (+116%):** Option B is moderately\n",
        "  slower and more expensive per query, as expected from the larger semantic\n",
        "  chunks and metadata extraction pipeline. The latency overhead is modest, and\n",
        "  the token and cost premium is justified by the quality gains across all five\n",
        "  RAGAS metrics.\n",
        "\n",
        "**Conclusion:** Option B is the clear winner across every quality dimension.\n",
        "The metadata extraction and semantic chunking strategy delivers its intended\n",
        "value: context recall nearly triples, faithfulness approaches 0.95, and entity\n",
        "recall improves meaningfully even without activated filtered retrieval. The\n",
        "latency and cost overhead is acceptable given the quality uplift. Potential next steps:\n",
        "activate metadata-filtered Qdrant retrieval at query time and tune semantic\n",
        "chunk thresholds to further reduce the token and cost premium?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
